<?xml version="1.0"?>

<launch>
    <!-- +++++++NOTE: The different paths in the args must be modified for your machine. ++++++++ -->
    <arg name="sim"                     default="true"/>
    <arg name="object_datasets_folder"  default="/home/vm/object_datasets"/>
    <arg name="object_point_cloud_path" default="/home/vm/object.pcd"/>
    <arg name="scene_point_cloud_path"  default="/home/vm/scene.pcd"/>
    <arg name="color_img_save_path"     default="/home/vm/scene.ppm"/>
    <arg name="depth_img_save_path"     default="/home/vm/depth.pgm"/>
    <arg name="launch_conda"            default="false"/>
    <!-- +++++++++++++++++++++++++++++++++++++++++++++++++++ -->
    <param name="object_point_cloud_path" value="$(arg object_point_cloud_path)" type="string" />
    <param name="scene_point_cloud_path"  value="$(arg scene_point_cloud_path)" type="string" />
    <param name="object_datasets_folder"  value="$(arg object_datasets_folder)" type="string" />
    <param name="color_img_save_path"  value="$(arg color_img_save_path)" type="string" />
    <param name="depth_img_save_path"  value="$(arg depth_img_save_path)" type="string" />
    <!-- +++++++++++++++++++++++++++++++++++++++++++++++++++ -->
    <!-- Publish the paths of scene and object point cloud-->
    <node name="point_cloud_save_publisher_node" pkg="grasp_pipeline" type="publish_point_cloud_save_path.py" output="screen"/>


    <!-- Manage moveit scene -->
    <node name="manage_moveit_scene_node" pkg="grasp_pipeline"
        type="manage_moveit_scene_server.py" output="screen">
        <param name="sim" type="bool" value="$(arg sim)"/>
    </node>

    <!-- num_samples_per_preshape: How many samples of slightly different poses will be generated. Always assumes the bounding box face center point + some distance outward in the object point normal direction as reference and samples the preshapes around that by adding some 3D noise specified in subsequent variables-->
    <!-- palm_dist_to_top_face_mean: When sampling poses around the top bounding box face center points how much do you on average go outward in the normal direction-->
    <!-- palm_dist_to_side_face_mean: When sampling poses around the side bounding box face center points how much do you on average go outward in the normal direction-->
    <!-- palm_dist_normal_to_obj_var: Variance for previous explained "going outward in normal direction"-->
    <!-- palm_position_3D_sample_var: Add some extra zero mean 3D position noise-->

   <!-- Grasp preshape -->
    <node name="generate_hithand_preshape_server_node" pkg="grasp_pipeline" 
        type="generate_hithand_preshape_server.py" output="screen">
      <param name="num_samples_per_preshape"     value="30"        type="int"/> 
      <param name="palm_dist_to_top_face_mean"   value="0.07"     type="double"/> 
      <param name="palm_dist_to_side_face_mean"  value="0.07"     type="double"/> 
      <param name="palm_dist_normal_to_obj_var"  value="0.0"      type="double"/> 
      <param name="palm_position_3D_sample_var"  value="0.0"      type="double"/> 
      <param name="wrist_roll_orientation_var"   value="0.1"      type="double"/>
      <param name="min_object_height"            value="0.03"     type="double"/>
    </node> 


    <!-- Moveit planner node for panda arm -->
    <node name="arm_moveit_planner_server_node" pkg="grasp_pipeline" type="arm_moveit_planner_server.py" output="screen"/>

    <!-- SMOOTH THE TRAJECTORY /-->
    <node name="get_smooth_trajectory_node" pkg="trajectory_smoothing" type="service" output="screen"/>

    <!-- Execute planned joint trajectory server-->
    <node name="execute_joint_trajectory_server_node" pkg="grasp_pipeline" type="execute_joint_trajectory_server.py" output="screen"/>


    <!-- Save visual data node -->
    <node name="save_visual_data_node" pkg="grasp_pipeline" type="save_visual_data_server.py" output="screen"/>


    <group if="$(arg sim)">
        <!-- Gazebo scene manager -->
        <node name="manage_gazebo_scene_node" pkg="grasp_pipeline" type="manage_gazebo_scene_server.py" output="screen"/>
        <!-- Hithand control manager -->
        <node name="control_hithand_config_node" pkg="grasp_pipeline" type="control_sim_hithand_server.py" output="screen"/>
        <!-- Camera transformation broadcaster -->
        <node name="camera_transform_broadcaster_node" pkg="grasp_pipeline" type="camera_transform_broadcaster.py" output="screen"/>
        <!-- Hand closing controller -->
        <node name="grasp_control_hithand_node" pkg="grasp_pipeline" type="grasp_control_sim_hithand_server.py" output="screen"/>
    </group>


    <!--Launch node which advertises service to segment the table from an object -->
    <node name="table_object_segmentation_node" pkg="grasp_pipeline" type="segment_object_server.py" output="screen"/>

    <!-- This launches the old segmenter written in python 3 -->
    <!-- <group if="$(arg launch_conda)">
	  <node name="table_object_segmentation_node" pkg="grasp_pipeline" type="table_object_segmenter_conda.sh" output="screen"/>
    </group> -->
   
</launch>
